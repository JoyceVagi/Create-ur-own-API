#  Create Your Own LLM-Powered API

This project is a simple and secure API built with **FastAPI** that allows users to interact with a local **LLM (via Ollama)**. It includes API key verification with credit limits and is ideal for understanding how to deploy and secure language model endpoints.

---

##  Features

-  Built with **FastAPI**
-  API key authentication with credit tracking
-  Local LLM chat using **Ollama + Mistral**
-  Secure secrets handling via `.env`
-  Tested using **Postman** and Python `requests`

---

##  Requirements

Install dependencies using:

```bash
pip install -r requirements.txt
